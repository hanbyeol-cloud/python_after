{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f56ebd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a22e514aa2f1>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-a22e514aa2f1>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    - 모델을 생성 ( Sequential, functional, Model)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#작업 순서\n",
    "- 데이터준비 (정규화, 차수일치)\n",
    "- 모델을 생성 ( Sequential, functional, Model)\n",
    "    - layer를 활용(Conv2d, Dense, Flatten, MaxPooling2D)\n",
    "- complie\n",
    "- fitting\n",
    "- save_weights, load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed07d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# channel, fillter, kernel, stride, padding\n",
    "# 마지막이 FFNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a02503",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# 정규화 -> -0.5 ~ 0.5 학습이 용이\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "# 원래 이미지 3차원 흑백 1바이트 60000X28X28 X1\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "num_filters = 8 # 필터의 개수\n",
    "filter_size = 3 # 사이즈 3X3\n",
    "pool_size = 2 #  합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b686964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #1장의 사이즈를 기재\n",
    "    Conv2D(num_filters, filter_size, input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.5), # 과적합을 방지하기 위해서 계산회로의 일부를 무작위로 제외\n",
    "    Flatten(), # FFNN fully-connected\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax') #확률값\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a1a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3442 - accuracy: 0.8939 - val_loss: 0.1434 - val_accuracy: 0.9572\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1699 - accuracy: 0.9475 - val_loss: 0.0877 - val_accuracy: 0.9729\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1291 - accuracy: 0.9598 - val_loss: 0.0786 - val_accuracy: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1acacf139a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(# train, validation, test\n",
    "    train_images,\n",
    "    to_categorical(train_labels), # 0.1\n",
    "    epochs=3,\n",
    "    validation_data=(test_images, to_categorical(test_labels))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ff6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35dc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "model = Sequential([\n",
    "    Conv2D(num_filters, filter_size, input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.load_weights('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e5827a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images[:5]) #확률값\n",
    "print(np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a8f8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1352 * 10 + bias\n",
    "\n",
    "# 왜 80인가\n",
    "가중치 사이즈의 공간\n",
    "8X3X3+8 bacth_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57877cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                86592     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 87,322\n",
      "Trainable params: 87,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e7d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(x_train.shape) # 60000 28 28\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c43153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((\n",
    "    x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23e88200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재사용성이 높아지고 , debugging이 용이, design pattern을 사용\n",
    "class MyModel(Model): # Sequential, functional, Model\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__() # 명시적으로 부모의 생성자를 호출\n",
    "        self.conv1 = Conv2D(32,3,activation='relu') # 인스턴스\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu') # 특징 추출\n",
    "        self.d2 = Dense(10, activation='softmax') # 출력\n",
    "    def call(self, x): # 클래스를 함수처럼 호출가능\n",
    "        x = self.conv1(x) # 실행\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac836f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses, metrics, optimizers wrapper 감싸게\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam() # runing rate 를 adaptive + zigzag : 가던방향을 고려해주면됨\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name = 'train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2950441",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # decorator 장식자 : debugging이 끝나기전에 달지 말아라\n",
    "    # 최적화된 프로그램의 변수(상수화가능한)를 상수화해서 속도를 빠르게 실행\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape: # 저장기능 : 변화량을 구하기 위해\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables) \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d692a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    # 레이블 : [0,0,0,1,0,0,0,0,0] one- hot- encoding\n",
    "    # predictions => softmax\n",
    "    # [확률값 10개 나옴]\n",
    "    # 3을 구하는 함수 argmax\n",
    "    # 실제값 == 예측값 맞으면 True, 틀리면 False => 1인 것을 다 더하고 개수를 나누면 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d499619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "에포크 : 1, 손실: 0.1362294703722, 정확도: 95.97166442871094, 테스트 손실: 0.05992317944765091, 테스트 정확도: 98.00999450683594\n",
      "에포크 : 2, 손실: 0.08895789831876755, 정확도: 97.3258285522461, 테스트 손실: 0.05720425024628639, 테스트 정확도: 98.09500122070312\n",
      "에포크 : 3, 손실: 0.06664854288101196, 정확도: 97.9705581665039, 테스트 손실: 0.05709094926714897, 테스트 정확도: 98.11666870117188\n",
      "에포크 : 4, 손실: 0.05336311459541321, 정확도: 98.36917114257812, 테스트 손실: 0.05680856481194496, 테스트 정확도: 98.21749877929688\n",
      "에포크 : 5, 손실: 0.04471927881240845, 정확도: 98.62200164794922, 테스트 손실: 0.05801577866077423, 테스트 정확도: 98.25\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "    template = '에포크 : {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "889ec95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#callbacks: 시스템(window)이 호출하는 함수 (마우스 이벤트 -)\n",
    "#시스템에 있는 event queue에 담김)\n",
    "#상황이나 상태에 따라 실행되는 함수\n",
    "\n",
    "# Earlystopping : 좋은 학습의 신호는 cost값을 작아지게 하는 것\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fce0153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(3)\n",
    "# 784, TARGET : 3\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() # 784 FFNN\n",
    "# CNN 원래 이미지로 복원\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3040ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "def bfn(optimizer = 'adam',learning_rate = 0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ddbc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "new_model = KerasClassifier(build_fn=bfn, epochs=30, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb457935",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'optimizer' : [\"Adam\",\"RMSProp\"],\n",
    "             'learning_rate' : [0.0025,0.001]}\n",
    "clf=GridSearchCV(estimator=new_model, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f9a23ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.9221 - acc: 0.7001 - val_loss: 0.1977 - val_acc: 0.9430\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3020 - acc: 0.9137 - val_loss: 0.1331 - val_acc: 0.9603\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2267 - acc: 0.9355 - val_loss: 0.1014 - val_acc: 0.9701\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1855 - acc: 0.9465 - val_loss: 0.0898 - val_acc: 0.9739\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1585 - acc: 0.9556 - val_loss: 0.0861 - val_acc: 0.9747\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1460 - acc: 0.9590 - val_loss: 0.0791 - val_acc: 0.9780\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1309 - acc: 0.9629 - val_loss: 0.0764 - val_acc: 0.9787\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1210 - acc: 0.9656 - val_loss: 0.0691 - val_acc: 0.9809\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1131 - acc: 0.9681 - val_loss: 0.0635 - val_acc: 0.9821\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1068 - acc: 0.9704 - val_loss: 0.0623 - val_acc: 0.9834\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1013 - acc: 0.9721 - val_loss: 0.0649 - val_acc: 0.9816\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0956 - acc: 0.9735 - val_loss: 0.0643 - val_acc: 0.9822\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0917 - acc: 0.9740 - val_loss: 0.0580 - val_acc: 0.9835\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0827 - acc: 0.9763 - val_loss: 0.0643 - val_acc: 0.9809\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0816 - acc: 0.9768 - val_loss: 0.0608 - val_acc: 0.9824\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0749 - acc: 0.9790 - val_loss: 0.0577 - val_acc: 0.9853\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0749 - acc: 0.9791 - val_loss: 0.0597 - val_acc: 0.9842\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0730 - acc: 0.9794 - val_loss: 0.0603 - val_acc: 0.9853\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0675 - acc: 0.9808 - val_loss: 0.0545 - val_acc: 0.9855\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0654 - acc: 0.9812 - val_loss: 0.0533 - val_acc: 0.9863\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0627 - acc: 0.9821 - val_loss: 0.0565 - val_acc: 0.9863\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0588 - acc: 0.9834 - val_loss: 0.0546 - val_acc: 0.9868\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0585 - acc: 0.9827 - val_loss: 0.0534 - val_acc: 0.9863\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0562 - acc: 0.9836 - val_loss: 0.0577 - val_acc: 0.9842\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0526 - acc: 0.9846 - val_loss: 0.0607 - val_acc: 0.9856\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0523 - acc: 0.9847 - val_loss: 0.0531 - val_acc: 0.9870\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0492 - acc: 0.9860 - val_loss: 0.0538 - val_acc: 0.9863\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0480 - acc: 0.9861 - val_loss: 0.0576 - val_acc: 0.9869\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0443 - acc: 0.9869 - val_loss: 0.0592 - val_acc: 0.9859\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0444 - acc: 0.9867 - val_loss: 0.0581 - val_acc: 0.9868\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0591 - acc: 0.9856\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.9017 - acc: 0.7092 - val_loss: 0.2046 - val_acc: 0.9411\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2951 - acc: 0.9149 - val_loss: 0.1284 - val_acc: 0.9620\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2155 - acc: 0.9386 - val_loss: 0.0951 - val_acc: 0.9715\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1738 - acc: 0.9512 - val_loss: 0.0911 - val_acc: 0.9718\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1482 - acc: 0.9590 - val_loss: 0.0822 - val_acc: 0.9753\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1325 - acc: 0.9628 - val_loss: 0.0813 - val_acc: 0.9770\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1211 - acc: 0.9663 - val_loss: 0.0688 - val_acc: 0.9795\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1101 - acc: 0.9688 - val_loss: 0.0716 - val_acc: 0.9791\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1047 - acc: 0.9709 - val_loss: 0.0641 - val_acc: 0.9809\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0984 - acc: 0.9721 - val_loss: 0.0644 - val_acc: 0.9810\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0902 - acc: 0.9757 - val_loss: 0.0622 - val_acc: 0.9825\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0836 - acc: 0.9769 - val_loss: 0.0639 - val_acc: 0.9826\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.0842 - acc: 0.9764 - val_loss: 0.0628 - val_acc: 0.9825\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0785 - acc: 0.9785 - val_loss: 0.0639 - val_acc: 0.9810\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0748 - acc: 0.9789 - val_loss: 0.0598 - val_acc: 0.9826\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0708 - acc: 0.9809 - val_loss: 0.0576 - val_acc: 0.9850\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0686 - acc: 0.9810 - val_loss: 0.0522 - val_acc: 0.9847\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0661 - acc: 0.9815 - val_loss: 0.0555 - val_acc: 0.9831\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0644 - acc: 0.9820 - val_loss: 0.0666 - val_acc: 0.9827\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0600 - acc: 0.9831 - val_loss: 0.0562 - val_acc: 0.9856\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0604 - acc: 0.9833 - val_loss: 0.0618 - val_acc: 0.9846\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.0566 - acc: 0.9841 - val_loss: 0.0587 - val_acc: 0.9854\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0519 - acc: 0.9850 - val_loss: 0.0552 - val_acc: 0.9860\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0500 - acc: 0.9861 - val_loss: 0.0566 - val_acc: 0.9863\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0488 - acc: 0.9861 - val_loss: 0.0557 - val_acc: 0.9859\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0477 - acc: 0.9860 - val_loss: 0.0545 - val_acc: 0.9868\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0475 - acc: 0.9868 - val_loss: 0.0563 - val_acc: 0.9849\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0486 - acc: 0.9860 - val_loss: 0.0597 - val_acc: 0.9838\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0469 - acc: 0.9864 - val_loss: 0.0583 - val_acc: 0.9849\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0422 - acc: 0.9877 - val_loss: 0.0618 - val_acc: 0.9864\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0559 - acc: 0.9850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.9383 - acc: 0.6938 - val_loss: 0.2322 - val_acc: 0.9325\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3382 - acc: 0.9032 - val_loss: 0.1396 - val_acc: 0.9590\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2370 - acc: 0.9329 - val_loss: 0.1134 - val_acc: 0.9654\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1950 - acc: 0.9452 - val_loss: 0.0913 - val_acc: 0.9725\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1702 - acc: 0.9528 - val_loss: 0.0894 - val_acc: 0.9747\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1490 - acc: 0.9595 - val_loss: 0.0829 - val_acc: 0.9761\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1352 - acc: 0.9626 - val_loss: 0.0803 - val_acc: 0.9777\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1214 - acc: 0.9666 - val_loss: 0.0753 - val_acc: 0.9782\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1140 - acc: 0.9694 - val_loss: 0.0708 - val_acc: 0.9789\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1050 - acc: 0.9712 - val_loss: 0.0695 - val_acc: 0.9811\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1014 - acc: 0.9717 - val_loss: 0.0670 - val_acc: 0.9823\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0936 - acc: 0.9755 - val_loss: 0.0713 - val_acc: 0.9805\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0905 - acc: 0.9753 - val_loss: 0.0662 - val_acc: 0.9813\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0842 - acc: 0.9769 - val_loss: 0.0616 - val_acc: 0.9833\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0775 - acc: 0.9779 - val_loss: 0.0653 - val_acc: 0.9815\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0763 - acc: 0.9788 - val_loss: 0.0625 - val_acc: 0.9832\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0749 - acc: 0.9791 - val_loss: 0.0601 - val_acc: 0.9836\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0713 - acc: 0.9805 - val_loss: 0.0544 - val_acc: 0.9854\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0689 - acc: 0.9808 - val_loss: 0.0640 - val_acc: 0.9838\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0633 - acc: 0.9823 - val_loss: 0.0554 - val_acc: 0.9849\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0658 - acc: 0.9824 - val_loss: 0.0586 - val_acc: 0.9842\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0587 - acc: 0.9836 - val_loss: 0.0526 - val_acc: 0.9853\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0581 - acc: 0.9840 - val_loss: 0.0536 - val_acc: 0.9856\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0563 - acc: 0.9843 - val_loss: 0.0566 - val_acc: 0.9862\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0547 - acc: 0.9847 - val_loss: 0.0538 - val_acc: 0.9853\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0536 - acc: 0.9849 - val_loss: 0.0570 - val_acc: 0.9844\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0508 - acc: 0.9863 - val_loss: 0.0566 - val_acc: 0.9846\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0508 - acc: 0.9858 - val_loss: 0.0597 - val_acc: 0.9847\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0484 - acc: 0.9863 - val_loss: 0.0556 - val_acc: 0.9849\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0454 - acc: 0.9866 - val_loss: 0.0608 - val_acc: 0.9854\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0611 - acc: 0.9841\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.9327 - acc: 0.6955 - val_loss: 0.2183 - val_acc: 0.9332\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3127 - acc: 0.9111 - val_loss: 0.1227 - val_acc: 0.9625\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2268 - acc: 0.9344 - val_loss: 0.0998 - val_acc: 0.9686\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1824 - acc: 0.9498 - val_loss: 0.0907 - val_acc: 0.9719\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1634 - acc: 0.9545 - val_loss: 0.0808 - val_acc: 0.9751\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1469 - acc: 0.9601 - val_loss: 0.0796 - val_acc: 0.9769\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1311 - acc: 0.9632 - val_loss: 0.0721 - val_acc: 0.9773\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1184 - acc: 0.9672 - val_loss: 0.0727 - val_acc: 0.9781\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1125 - acc: 0.9690 - val_loss: 0.0688 - val_acc: 0.9796\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1061 - acc: 0.9708 - val_loss: 0.0625 - val_acc: 0.9810\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0960 - acc: 0.9732 - val_loss: 0.0633 - val_acc: 0.9809\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0917 - acc: 0.9741 - val_loss: 0.0583 - val_acc: 0.9823\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0869 - acc: 0.9755 - val_loss: 0.0606 - val_acc: 0.9830\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0819 - acc: 0.9776 - val_loss: 0.0609 - val_acc: 0.9824\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0810 - acc: 0.9775 - val_loss: 0.0604 - val_acc: 0.9825\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0730 - acc: 0.9794 - val_loss: 0.0582 - val_acc: 0.9832\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0751 - acc: 0.9794 - val_loss: 0.0576 - val_acc: 0.9827\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0690 - acc: 0.9809 - val_loss: 0.0597 - val_acc: 0.9833\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0684 - acc: 0.9807 - val_loss: 0.0573 - val_acc: 0.9840\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0637 - acc: 0.9825 - val_loss: 0.0683 - val_acc: 0.9816\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0639 - acc: 0.9820 - val_loss: 0.0557 - val_acc: 0.9848\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0591 - acc: 0.9831 - val_loss: 0.0588 - val_acc: 0.9847\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0603 - acc: 0.9833 - val_loss: 0.0542 - val_acc: 0.9858\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0576 - acc: 0.9837 - val_loss: 0.0601 - val_acc: 0.9833\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0545 - acc: 0.9847 - val_loss: 0.0550 - val_acc: 0.9853\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0534 - acc: 0.9847 - val_loss: 0.0676 - val_acc: 0.9825\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0514 - acc: 0.9850 - val_loss: 0.0662 - val_acc: 0.9833\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0520 - acc: 0.9854 - val_loss: 0.0567 - val_acc: 0.9846\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0485 - acc: 0.9862 - val_loss: 0.0566 - val_acc: 0.9847\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.0447 - acc: 0.9878 - val_loss: 0.0577 - val_acc: 0.9847\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0648 - acc: 0.9842\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 33ms/step - loss: 0.9243 - acc: 0.6939 - val_loss: 0.2185 - val_acc: 0.9340\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3193 - acc: 0.9072 - val_loss: 0.1338 - val_acc: 0.9611\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2333 - acc: 0.9354 - val_loss: 0.0995 - val_acc: 0.9684\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1922 - acc: 0.9461 - val_loss: 0.0819 - val_acc: 0.9746\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1641 - acc: 0.9541 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1454 - acc: 0.9591 - val_loss: 0.0734 - val_acc: 0.9773\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1346 - acc: 0.9622 - val_loss: 0.0698 - val_acc: 0.9801\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1200 - acc: 0.9666 - val_loss: 0.0659 - val_acc: 0.9792\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1117 - acc: 0.9682 - val_loss: 0.0633 - val_acc: 0.9820\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1049 - acc: 0.9706 - val_loss: 0.0642 - val_acc: 0.9816\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1007 - acc: 0.9721 - val_loss: 0.0590 - val_acc: 0.9830\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0952 - acc: 0.9737 - val_loss: 0.0672 - val_acc: 0.9805\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0879 - acc: 0.9757 - val_loss: 0.0587 - val_acc: 0.9843\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0824 - acc: 0.9768 - val_loss: 0.0528 - val_acc: 0.9860\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0792 - acc: 0.9774 - val_loss: 0.0546 - val_acc: 0.9841\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0775 - acc: 0.9779 - val_loss: 0.0564 - val_acc: 0.9838\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0689 - acc: 0.9805 - val_loss: 0.0579 - val_acc: 0.9835\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0697 - acc: 0.9799 - val_loss: 0.0550 - val_acc: 0.9857\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0677 - acc: 0.9807 - val_loss: 0.0517 - val_acc: 0.9854\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0642 - acc: 0.9820 - val_loss: 0.0581 - val_acc: 0.9853\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0636 - acc: 0.9823 - val_loss: 0.0487 - val_acc: 0.9870\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0577 - acc: 0.9827 - val_loss: 0.0549 - val_acc: 0.9853\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0566 - acc: 0.9839 - val_loss: 0.0531 - val_acc: 0.9861\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0543 - acc: 0.9841 - val_loss: 0.0514 - val_acc: 0.9863\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0554 - acc: 0.9845 - val_loss: 0.0524 - val_acc: 0.9855\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0520 - acc: 0.9846 - val_loss: 0.0512 - val_acc: 0.9849\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0495 - acc: 0.9854 - val_loss: 0.0483 - val_acc: 0.9875\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0495 - acc: 0.9860 - val_loss: 0.0491 - val_acc: 0.9875\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0476 - acc: 0.9864 - val_loss: 0.0517 - val_acc: 0.9852\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0434 - acc: 0.9873 - val_loss: 0.0497 - val_acc: 0.9867\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0532 - acc: 0.9869\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.0304 - acc: 0.6660 - val_loss: 0.2857 - val_acc: 0.9140\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.3853 - acc: 0.8864 - val_loss: 0.1613 - val_acc: 0.9491\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2606 - acc: 0.9253 - val_loss: 0.1105 - val_acc: 0.9670\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2044 - acc: 0.9426 - val_loss: 0.1025 - val_acc: 0.9703\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.1669 - acc: 0.9536 - val_loss: 0.1061 - val_acc: 0.9686\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1456 - acc: 0.9605 - val_loss: 0.0837 - val_acc: 0.9759\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1314 - acc: 0.9639 - val_loss: 0.0762 - val_acc: 0.9783\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1155 - acc: 0.9684 - val_loss: 0.0721 - val_acc: 0.9808\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1065 - acc: 0.9709 - val_loss: 0.0669 - val_acc: 0.9820\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0978 - acc: 0.9739 - val_loss: 0.0733 - val_acc: 0.9800\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0911 - acc: 0.9750 - val_loss: 0.0716 - val_acc: 0.9822\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0855 - acc: 0.9769 - val_loss: 0.0596 - val_acc: 0.9837\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0807 - acc: 0.9776 - val_loss: 0.0718 - val_acc: 0.9811\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0771 - acc: 0.9788 - val_loss: 0.0681 - val_acc: 0.9818\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0742 - acc: 0.9800 - val_loss: 0.0609 - val_acc: 0.9845\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0684 - acc: 0.9808 - val_loss: 0.0575 - val_acc: 0.9849\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0646 - acc: 0.9820 - val_loss: 0.0669 - val_acc: 0.9839\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0638 - acc: 0.9822 - val_loss: 0.0597 - val_acc: 0.9856\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0595 - acc: 0.9834 - val_loss: 0.0714 - val_acc: 0.9844\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0564 - acc: 0.9842 - val_loss: 0.0618 - val_acc: 0.9856\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0554 - acc: 0.9848 - val_loss: 0.0621 - val_acc: 0.9849\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0530 - acc: 0.9852 - val_loss: 0.0577 - val_acc: 0.9868\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0503 - acc: 0.9861 - val_loss: 0.0640 - val_acc: 0.9875\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0507 - acc: 0.9860 - val_loss: 0.0620 - val_acc: 0.9846\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0482 - acc: 0.9864 - val_loss: 0.0586 - val_acc: 0.9863\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0472 - acc: 0.9865 - val_loss: 0.0588 - val_acc: 0.9863\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0450 - acc: 0.9870 - val_loss: 0.0739 - val_acc: 0.9840\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0451 - acc: 0.9874 - val_loss: 0.0570 - val_acc: 0.9867\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0419 - acc: 0.9881 - val_loss: 0.0602 - val_acc: 0.9872\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0419 - acc: 0.9887 - val_loss: 0.0668 - val_acc: 0.9854\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0615 - acc: 0.9861\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 35ms/step - loss: 0.9788 - acc: 0.6844 - val_loss: 0.2566 - val_acc: 0.9266\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3519 - acc: 0.8979 - val_loss: 0.1943 - val_acc: 0.9395\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2435 - acc: 0.9300 - val_loss: 0.1109 - val_acc: 0.9660\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1914 - acc: 0.9456 - val_loss: 0.0991 - val_acc: 0.9722\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1627 - acc: 0.9551 - val_loss: 0.0851 - val_acc: 0.9735\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1382 - acc: 0.9613 - val_loss: 0.0845 - val_acc: 0.9762\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1289 - acc: 0.9650 - val_loss: 0.0758 - val_acc: 0.9785\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1145 - acc: 0.9690 - val_loss: 0.0783 - val_acc: 0.9782\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1051 - acc: 0.9713 - val_loss: 0.0667 - val_acc: 0.9815\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0951 - acc: 0.9746 - val_loss: 0.0673 - val_acc: 0.9806\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0945 - acc: 0.9746 - val_loss: 0.0717 - val_acc: 0.9802\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0860 - acc: 0.9767 - val_loss: 0.0579 - val_acc: 0.9848\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0795 - acc: 0.9784 - val_loss: 0.0653 - val_acc: 0.9833\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0742 - acc: 0.9796 - val_loss: 0.0599 - val_acc: 0.9837\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0704 - acc: 0.9808 - val_loss: 0.0646 - val_acc: 0.9839\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0662 - acc: 0.9819 - val_loss: 0.0658 - val_acc: 0.9838\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0674 - acc: 0.9813 - val_loss: 0.0600 - val_acc: 0.9857\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0615 - acc: 0.9835 - val_loss: 0.0688 - val_acc: 0.9830\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0592 - acc: 0.9833 - val_loss: 0.0582 - val_acc: 0.9857\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0561 - acc: 0.9842 - val_loss: 0.0644 - val_acc: 0.9823\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0518 - acc: 0.9853 - val_loss: 0.0632 - val_acc: 0.9859\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0517 - acc: 0.9854 - val_loss: 0.0633 - val_acc: 0.9850\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0513 - acc: 0.9858 - val_loss: 0.0643 - val_acc: 0.9855\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0483 - acc: 0.9868 - val_loss: 0.0576 - val_acc: 0.9856\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0481 - acc: 0.9866 - val_loss: 0.0572 - val_acc: 0.9861\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0449 - acc: 0.9873 - val_loss: 0.0559 - val_acc: 0.9867\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0432 - acc: 0.9881 - val_loss: 0.0544 - val_acc: 0.9867\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0439 - acc: 0.9871 - val_loss: 0.0582 - val_acc: 0.9875\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0418 - acc: 0.9880 - val_loss: 0.0612 - val_acc: 0.9865\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0419 - acc: 0.9885 - val_loss: 0.0649 - val_acc: 0.9849\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0556 - acc: 0.9858\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.9167 - acc: 0.6997 - val_loss: 0.2472 - val_acc: 0.9241\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3446 - acc: 0.8995 - val_loss: 0.1476 - val_acc: 0.9535\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2342 - acc: 0.9320 - val_loss: 0.1117 - val_acc: 0.9645\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1890 - acc: 0.9464 - val_loss: 0.0995 - val_acc: 0.9679\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1619 - acc: 0.9557 - val_loss: 0.0876 - val_acc: 0.9725\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1418 - acc: 0.9607 - val_loss: 0.0740 - val_acc: 0.9772\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1270 - acc: 0.9640 - val_loss: 0.0707 - val_acc: 0.9787\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1138 - acc: 0.9674 - val_loss: 0.0740 - val_acc: 0.9781\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1040 - acc: 0.9715 - val_loss: 0.0623 - val_acc: 0.9813\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0943 - acc: 0.9742 - val_loss: 0.0660 - val_acc: 0.9809\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0919 - acc: 0.9749 - val_loss: 0.0603 - val_acc: 0.9831\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0866 - acc: 0.9766 - val_loss: 0.0602 - val_acc: 0.9835\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0798 - acc: 0.9775 - val_loss: 0.0610 - val_acc: 0.9834\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0761 - acc: 0.9792 - val_loss: 0.0589 - val_acc: 0.9823\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0700 - acc: 0.9806 - val_loss: 0.0570 - val_acc: 0.9850\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0688 - acc: 0.9809 - val_loss: 0.0569 - val_acc: 0.9826\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0644 - acc: 0.9821 - val_loss: 0.0545 - val_acc: 0.9854\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0603 - acc: 0.9834 - val_loss: 0.0544 - val_acc: 0.9840\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0587 - acc: 0.9835 - val_loss: 0.0587 - val_acc: 0.9850\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0586 - acc: 0.9837 - val_loss: 0.0522 - val_acc: 0.9860\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0543 - acc: 0.9852 - val_loss: 0.0547 - val_acc: 0.9864\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0534 - acc: 0.9853 - val_loss: 0.0556 - val_acc: 0.9850\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0513 - acc: 0.9860 - val_loss: 0.0574 - val_acc: 0.9853\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0493 - acc: 0.9861 - val_loss: 0.0616 - val_acc: 0.9834\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0489 - acc: 0.9871 - val_loss: 0.0552 - val_acc: 0.9865\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0479 - acc: 0.9865 - val_loss: 0.0593 - val_acc: 0.9863\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0447 - acc: 0.9878 - val_loss: 0.0600 - val_acc: 0.9855\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0429 - acc: 0.9882 - val_loss: 0.0536 - val_acc: 0.9865\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0430 - acc: 0.9885 - val_loss: 0.0545 - val_acc: 0.9860\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0414 - acc: 0.9882 - val_loss: 0.0659 - val_acc: 0.9851\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0641 - acc: 0.9822\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 35ms/step - loss: 0.9418 - acc: 0.6941 - val_loss: 0.2006 - val_acc: 0.9403\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3108 - acc: 0.9115 - val_loss: 0.1276 - val_acc: 0.9608\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2124 - acc: 0.9405 - val_loss: 0.0953 - val_acc: 0.9716\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1676 - acc: 0.9535 - val_loss: 0.0878 - val_acc: 0.9731\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1406 - acc: 0.9609 - val_loss: 0.0761 - val_acc: 0.9766\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1234 - acc: 0.9655 - val_loss: 0.0777 - val_acc: 0.9773\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1124 - acc: 0.9693 - val_loss: 0.0674 - val_acc: 0.9786\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1032 - acc: 0.9712 - val_loss: 0.0639 - val_acc: 0.9809\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0944 - acc: 0.9744 - val_loss: 0.0805 - val_acc: 0.9764\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0891 - acc: 0.9759 - val_loss: 0.0766 - val_acc: 0.9788\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0808 - acc: 0.9781 - val_loss: 0.0573 - val_acc: 0.9835\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0754 - acc: 0.9801 - val_loss: 0.0541 - val_acc: 0.9843\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0740 - acc: 0.9794 - val_loss: 0.0562 - val_acc: 0.9845\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0675 - acc: 0.9816 - val_loss: 0.0579 - val_acc: 0.9849\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0647 - acc: 0.9826 - val_loss: 0.0598 - val_acc: 0.9846\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0622 - acc: 0.9827 - val_loss: 0.0594 - val_acc: 0.9840\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0589 - acc: 0.9836 - val_loss: 0.0636 - val_acc: 0.9846\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0554 - acc: 0.9844 - val_loss: 0.0583 - val_acc: 0.9834\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0550 - acc: 0.9852 - val_loss: 0.0609 - val_acc: 0.9855\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0499 - acc: 0.9862 - val_loss: 0.0563 - val_acc: 0.9856\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0513 - acc: 0.9860 - val_loss: 0.0607 - val_acc: 0.9845\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0475 - acc: 0.9872 - val_loss: 0.0567 - val_acc: 0.9862\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0500 - acc: 0.9868 - val_loss: 0.0586 - val_acc: 0.9856\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0453 - acc: 0.9872 - val_loss: 0.0545 - val_acc: 0.9852\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0428 - acc: 0.9882 - val_loss: 0.0625 - val_acc: 0.9870\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0455 - acc: 0.9881 - val_loss: 0.0567 - val_acc: 0.9859\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0426 - acc: 0.9883 - val_loss: 0.0752 - val_acc: 0.9829\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0402 - acc: 0.9887 - val_loss: 0.0796 - val_acc: 0.9818\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0405 - acc: 0.9887 - val_loss: 0.0594 - val_acc: 0.9851\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0374 - acc: 0.9898 - val_loss: 0.0591 - val_acc: 0.9862\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0747 - acc: 0.9841\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.9842 - acc: 0.6851 - val_loss: 0.2287 - val_acc: 0.9353\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3562 - acc: 0.8963 - val_loss: 0.1381 - val_acc: 0.9577\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2443 - acc: 0.9304 - val_loss: 0.1029 - val_acc: 0.9695\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1891 - acc: 0.9467 - val_loss: 0.0929 - val_acc: 0.9725\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1570 - acc: 0.9564 - val_loss: 0.0850 - val_acc: 0.9755\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1343 - acc: 0.9625 - val_loss: 0.0740 - val_acc: 0.9784\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1225 - acc: 0.9657 - val_loss: 0.0678 - val_acc: 0.9813\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1092 - acc: 0.9703 - val_loss: 0.0682 - val_acc: 0.9815\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1024 - acc: 0.9720 - val_loss: 0.0574 - val_acc: 0.9833\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0939 - acc: 0.9739 - val_loss: 0.0552 - val_acc: 0.9838\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0900 - acc: 0.9753 - val_loss: 0.0547 - val_acc: 0.9853\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0828 - acc: 0.9771 - val_loss: 0.0656 - val_acc: 0.9826\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0782 - acc: 0.9782 - val_loss: 0.0599 - val_acc: 0.9837\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0741 - acc: 0.9797 - val_loss: 0.0521 - val_acc: 0.9855\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0696 - acc: 0.9810 - val_loss: 0.0555 - val_acc: 0.9858\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0670 - acc: 0.9816 - val_loss: 0.0540 - val_acc: 0.9860\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0622 - acc: 0.9828 - val_loss: 0.0611 - val_acc: 0.9843\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0599 - acc: 0.9830 - val_loss: 0.0526 - val_acc: 0.9855\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0562 - acc: 0.9840 - val_loss: 0.0566 - val_acc: 0.9853\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0539 - acc: 0.9845 - val_loss: 0.0620 - val_acc: 0.9843\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0542 - acc: 0.9848 - val_loss: 0.0572 - val_acc: 0.9855\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0526 - acc: 0.9855 - val_loss: 0.0540 - val_acc: 0.9857\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0491 - acc: 0.9857 - val_loss: 0.0570 - val_acc: 0.9875\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0490 - acc: 0.9860 - val_loss: 0.0538 - val_acc: 0.9877\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0489 - acc: 0.9859 - val_loss: 0.0584 - val_acc: 0.9863\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0457 - acc: 0.9874 - val_loss: 0.0594 - val_acc: 0.9858\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0434 - acc: 0.9880 - val_loss: 0.0558 - val_acc: 0.9870\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0426 - acc: 0.9881 - val_loss: 0.0587 - val_acc: 0.9870\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0387 - acc: 0.9891 - val_loss: 0.0603 - val_acc: 0.9875\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0419 - acc: 0.9881 - val_loss: 0.0786 - val_acc: 0.9837\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.0735 - acc: 0.9836\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 35ms/step - loss: 0.8523 - acc: 0.7183 - val_loss: 0.1651 - val_acc: 0.9508\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2668 - acc: 0.9233 - val_loss: 0.1156 - val_acc: 0.9665\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1936 - acc: 0.9440 - val_loss: 0.0933 - val_acc: 0.9709\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1615 - acc: 0.9548 - val_loss: 0.0796 - val_acc: 0.9768\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1399 - acc: 0.9608 - val_loss: 0.0707 - val_acc: 0.9785\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1226 - acc: 0.9654 - val_loss: 0.0757 - val_acc: 0.9786\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1147 - acc: 0.9680 - val_loss: 0.0666 - val_acc: 0.9793\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1044 - acc: 0.9709 - val_loss: 0.0633 - val_acc: 0.9826\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0976 - acc: 0.9731 - val_loss: 0.0610 - val_acc: 0.9825\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0923 - acc: 0.9749 - val_loss: 0.0607 - val_acc: 0.9823\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 0.0860 - acc: 0.9758 - val_loss: 0.0606 - val_acc: 0.9817\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0814 - acc: 0.9779 - val_loss: 0.0608 - val_acc: 0.9833\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0782 - acc: 0.9778 - val_loss: 0.0591 - val_acc: 0.9830\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0734 - acc: 0.9787 - val_loss: 0.0508 - val_acc: 0.9851\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0685 - acc: 0.9812 - val_loss: 0.0570 - val_acc: 0.9844\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0671 - acc: 0.9811 - val_loss: 0.0510 - val_acc: 0.9849\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0635 - acc: 0.9819 - val_loss: 0.0547 - val_acc: 0.9859\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0625 - acc: 0.9821 - val_loss: 0.0573 - val_acc: 0.9844\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0598 - acc: 0.9821 - val_loss: 0.0618 - val_acc: 0.9836\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0557 - acc: 0.9839 - val_loss: 0.0612 - val_acc: 0.9835\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0562 - acc: 0.9837 - val_loss: 0.0543 - val_acc: 0.9862\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0536 - acc: 0.9857 - val_loss: 0.0554 - val_acc: 0.9849\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0512 - acc: 0.9851 - val_loss: 0.0505 - val_acc: 0.9857\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0485 - acc: 0.9857 - val_loss: 0.0567 - val_acc: 0.9849\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0463 - acc: 0.9867 - val_loss: 0.0540 - val_acc: 0.9866\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0435 - acc: 0.9871 - val_loss: 0.0587 - val_acc: 0.9846\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0628 - val_acc: 0.9845\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0415 - acc: 0.9875 - val_loss: 0.0549 - val_acc: 0.9871\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0423 - acc: 0.9879 - val_loss: 0.0528 - val_acc: 0.9865\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0414 - acc: 0.9879 - val_loss: 0.0541 - val_acc: 0.9873\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0648 - acc: 0.9858\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.9057 - acc: 0.7001 - val_loss: 0.1937 - val_acc: 0.9449\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2753 - acc: 0.9209 - val_loss: 0.1154 - val_acc: 0.9644\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2080 - acc: 0.9415 - val_loss: 0.0995 - val_acc: 0.9667\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1671 - acc: 0.9525 - val_loss: 0.0951 - val_acc: 0.9711\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1465 - acc: 0.9591 - val_loss: 0.0813 - val_acc: 0.9763\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1311 - acc: 0.9641 - val_loss: 0.0826 - val_acc: 0.9758\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1141 - acc: 0.9681 - val_loss: 0.0711 - val_acc: 0.9801\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1059 - acc: 0.9695 - val_loss: 0.0664 - val_acc: 0.9803\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0980 - acc: 0.9721 - val_loss: 0.0699 - val_acc: 0.9814\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0947 - acc: 0.9737 - val_loss: 0.0616 - val_acc: 0.9826\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0892 - acc: 0.9761 - val_loss: 0.0587 - val_acc: 0.9836\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0825 - acc: 0.9781 - val_loss: 0.0575 - val_acc: 0.9831\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0773 - acc: 0.9787 - val_loss: 0.0623 - val_acc: 0.9819\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0776 - acc: 0.9786 - val_loss: 0.0597 - val_acc: 0.9824\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0730 - acc: 0.9796 - val_loss: 0.0536 - val_acc: 0.9854\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0665 - acc: 0.9807 - val_loss: 0.0577 - val_acc: 0.9836\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0646 - acc: 0.9821 - val_loss: 0.0585 - val_acc: 0.9838\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0628 - acc: 0.9824 - val_loss: 0.0586 - val_acc: 0.9844\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0592 - acc: 0.9833 - val_loss: 0.0576 - val_acc: 0.9844\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0568 - acc: 0.9843 - val_loss: 0.0501 - val_acc: 0.9869\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0571 - acc: 0.9839 - val_loss: 0.0560 - val_acc: 0.9862\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0532 - acc: 0.9845 - val_loss: 0.0544 - val_acc: 0.9865\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0494 - acc: 0.9857 - val_loss: 0.0598 - val_acc: 0.9856\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0490 - acc: 0.9857 - val_loss: 0.0597 - val_acc: 0.9857\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0466 - acc: 0.9865 - val_loss: 0.0596 - val_acc: 0.9842\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0450 - acc: 0.9870 - val_loss: 0.0541 - val_acc: 0.9867\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.0465 - acc: 0.9865 - val_loss: 0.0592 - val_acc: 0.9864\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0423 - acc: 0.9886 - val_loss: 0.0565 - val_acc: 0.9852\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0420 - acc: 0.9878 - val_loss: 0.0524 - val_acc: 0.9867\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0382 - acc: 0.9888 - val_loss: 0.0634 - val_acc: 0.9853\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0533 - acc: 0.9858\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 9s 36ms/step - loss: 0.9141 - acc: 0.7083 - val_loss: 0.1945 - val_acc: 0.9423\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.3053 - acc: 0.9122 - val_loss: 0.1356 - val_acc: 0.9589\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.2236 - acc: 0.9376 - val_loss: 0.1109 - val_acc: 0.9661\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1857 - acc: 0.9477 - val_loss: 0.0962 - val_acc: 0.9700\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.1622 - acc: 0.9550 - val_loss: 0.0819 - val_acc: 0.9762\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.1418 - acc: 0.9606 - val_loss: 0.0758 - val_acc: 0.9777\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.1315 - acc: 0.9638 - val_loss: 0.0822 - val_acc: 0.9763\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1222 - acc: 0.9670 - val_loss: 0.0710 - val_acc: 0.9799\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1151 - acc: 0.9685 - val_loss: 0.0747 - val_acc: 0.9782\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1057 - acc: 0.9707 - val_loss: 0.0665 - val_acc: 0.9813\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0994 - acc: 0.9724 - val_loss: 0.0705 - val_acc: 0.9782\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0930 - acc: 0.9749 - val_loss: 0.0629 - val_acc: 0.9821\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0918 - acc: 0.9743 - val_loss: 0.0690 - val_acc: 0.9814\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0861 - acc: 0.9760 - val_loss: 0.0615 - val_acc: 0.9822\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0788 - acc: 0.9780 - val_loss: 0.0594 - val_acc: 0.9842\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0752 - acc: 0.9784 - val_loss: 0.0578 - val_acc: 0.9841\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0759 - acc: 0.9791 - val_loss: 0.0578 - val_acc: 0.9834\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0736 - acc: 0.9791 - val_loss: 0.0549 - val_acc: 0.9843\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0685 - acc: 0.9806 - val_loss: 0.0605 - val_acc: 0.9852\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0675 - acc: 0.9809 - val_loss: 0.0575 - val_acc: 0.9852\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0653 - acc: 0.9819 - val_loss: 0.0525 - val_acc: 0.9857\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0632 - acc: 0.9818 - val_loss: 0.0529 - val_acc: 0.9849\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0581 - acc: 0.9833 - val_loss: 0.0540 - val_acc: 0.9864\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0560 - acc: 0.9837 - val_loss: 0.0543 - val_acc: 0.9849\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0557 - acc: 0.9842 - val_loss: 0.0537 - val_acc: 0.9855\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0518 - acc: 0.9852 - val_loss: 0.0542 - val_acc: 0.9855\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0531 - acc: 0.9847 - val_loss: 0.0572 - val_acc: 0.9850\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0514 - acc: 0.9851 - val_loss: 0.0574 - val_acc: 0.9838\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0503 - acc: 0.9852 - val_loss: 0.0499 - val_acc: 0.9866\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0462 - acc: 0.9866 - val_loss: 0.0563 - val_acc: 0.9856\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0678 - acc: 0.9825\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.9037 - acc: 0.7017 - val_loss: 0.2112 - val_acc: 0.9345\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3113 - acc: 0.9112 - val_loss: 0.1403 - val_acc: 0.9557\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2232 - acc: 0.9373 - val_loss: 0.1046 - val_acc: 0.9684\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1799 - acc: 0.9497 - val_loss: 0.0912 - val_acc: 0.9732\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1552 - acc: 0.9569 - val_loss: 0.0903 - val_acc: 0.9718\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1382 - acc: 0.9618 - val_loss: 0.0798 - val_acc: 0.9758\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.1286 - acc: 0.9643 - val_loss: 0.0864 - val_acc: 0.9748\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.1110 - acc: 0.9686 - val_loss: 0.0751 - val_acc: 0.9773\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.1100 - acc: 0.9694 - val_loss: 0.0661 - val_acc: 0.9790\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0998 - acc: 0.9716 - val_loss: 0.0691 - val_acc: 0.9801\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0961 - acc: 0.9740 - val_loss: 0.0667 - val_acc: 0.9798\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0840 - acc: 0.9771 - val_loss: 0.0662 - val_acc: 0.9804\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0801 - acc: 0.9779 - val_loss: 0.0672 - val_acc: 0.9808\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0754 - acc: 0.9789 - val_loss: 0.0585 - val_acc: 0.9830\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0716 - acc: 0.9798 - val_loss: 0.0651 - val_acc: 0.9818\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0685 - acc: 0.9806 - val_loss: 0.0638 - val_acc: 0.9800\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0643 - acc: 0.9815 - val_loss: 0.0561 - val_acc: 0.9831\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0648 - acc: 0.9815 - val_loss: 0.0607 - val_acc: 0.9826\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0618 - acc: 0.9827 - val_loss: 0.0655 - val_acc: 0.9821\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0598 - acc: 0.9823 - val_loss: 0.0564 - val_acc: 0.9852\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0552 - acc: 0.9840 - val_loss: 0.0578 - val_acc: 0.9848\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0546 - acc: 0.9845 - val_loss: 0.0612 - val_acc: 0.9843\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0521 - acc: 0.9847 - val_loss: 0.0550 - val_acc: 0.9850\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0496 - acc: 0.9860 - val_loss: 0.0535 - val_acc: 0.9844\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0451 - acc: 0.9871 - val_loss: 0.0592 - val_acc: 0.9849\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0483 - acc: 0.9861 - val_loss: 0.0628 - val_acc: 0.9838\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0442 - acc: 0.9870 - val_loss: 0.0613 - val_acc: 0.9847\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0451 - acc: 0.9872 - val_loss: 0.0560 - val_acc: 0.9844\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0405 - acc: 0.9885 - val_loss: 0.0580 - val_acc: 0.9840\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0418 - acc: 0.9877 - val_loss: 0.0576 - val_acc: 0.9866\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0611 - acc: 0.9846\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 34ms/step - loss: 0.9704 - acc: 0.6772 - val_loss: 0.2347 - val_acc: 0.9317\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3258 - acc: 0.9030 - val_loss: 0.1358 - val_acc: 0.9589\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2381 - acc: 0.9326 - val_loss: 0.1173 - val_acc: 0.9641\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1965 - acc: 0.9446 - val_loss: 0.0978 - val_acc: 0.9711\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1687 - acc: 0.9535 - val_loss: 0.0922 - val_acc: 0.9724\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1535 - acc: 0.9570 - val_loss: 0.0940 - val_acc: 0.9729\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1382 - acc: 0.9625 - val_loss: 0.0762 - val_acc: 0.9765\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1253 - acc: 0.9645 - val_loss: 0.0742 - val_acc: 0.9794\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1169 - acc: 0.9679 - val_loss: 0.0660 - val_acc: 0.9807\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1117 - acc: 0.9700 - val_loss: 0.0684 - val_acc: 0.9814\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1040 - acc: 0.9723 - val_loss: 0.0632 - val_acc: 0.9820\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0998 - acc: 0.9718 - val_loss: 0.0623 - val_acc: 0.9810\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0923 - acc: 0.9741 - val_loss: 0.0612 - val_acc: 0.9839\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0843 - acc: 0.9772 - val_loss: 0.0571 - val_acc: 0.9841\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0825 - acc: 0.9769 - val_loss: 0.0670 - val_acc: 0.9815\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0797 - acc: 0.9777 - val_loss: 0.0640 - val_acc: 0.9821\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0755 - acc: 0.9793 - val_loss: 0.0562 - val_acc: 0.9856\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0718 - acc: 0.9803 - val_loss: 0.0624 - val_acc: 0.9834\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0683 - acc: 0.9807 - val_loss: 0.0562 - val_acc: 0.9849\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0654 - acc: 0.9818 - val_loss: 0.0663 - val_acc: 0.9840\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0660 - acc: 0.9818 - val_loss: 0.0532 - val_acc: 0.9854\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0608 - acc: 0.9831 - val_loss: 0.0611 - val_acc: 0.9846\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0581 - acc: 0.9841 - val_loss: 0.0522 - val_acc: 0.9866\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0594 - acc: 0.9839 - val_loss: 0.0600 - val_acc: 0.9849\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0529 - acc: 0.9848 - val_loss: 0.0581 - val_acc: 0.9860\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0537 - acc: 0.9851 - val_loss: 0.0598 - val_acc: 0.9853\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0527 - acc: 0.9853 - val_loss: 0.0605 - val_acc: 0.9848\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0529 - acc: 0.9848 - val_loss: 0.0529 - val_acc: 0.9873\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0481 - acc: 0.9866 - val_loss: 0.0525 - val_acc: 0.9869\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0448 - acc: 0.9871 - val_loss: 0.0530 - val_acc: 0.9864\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0499 - acc: 0.9871\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.0235 - acc: 0.6651 - val_loss: 0.2769 - val_acc: 0.9196\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3520 - acc: 0.8986 - val_loss: 0.1400 - val_acc: 0.9564\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2366 - acc: 0.9330 - val_loss: 0.1094 - val_acc: 0.9672\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1829 - acc: 0.9494 - val_loss: 0.0847 - val_acc: 0.9756\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1587 - acc: 0.9551 - val_loss: 0.0771 - val_acc: 0.9774\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1383 - acc: 0.9619 - val_loss: 0.0816 - val_acc: 0.9764\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1219 - acc: 0.9662 - val_loss: 0.0700 - val_acc: 0.9803\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1077 - acc: 0.9701 - val_loss: 0.0648 - val_acc: 0.9829\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.1029 - acc: 0.9713 - val_loss: 0.0629 - val_acc: 0.9825\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.0961 - acc: 0.9736 - val_loss: 0.0611 - val_acc: 0.9827\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0891 - acc: 0.9759 - val_loss: 0.0621 - val_acc: 0.9842\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0817 - acc: 0.9779 - val_loss: 0.0621 - val_acc: 0.9842\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0787 - acc: 0.9785 - val_loss: 0.0615 - val_acc: 0.9832\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0729 - acc: 0.9797 - val_loss: 0.0606 - val_acc: 0.9834\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0709 - acc: 0.9810 - val_loss: 0.0563 - val_acc: 0.9861\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0680 - acc: 0.9810 - val_loss: 0.0583 - val_acc: 0.9850\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0623 - acc: 0.9834 - val_loss: 0.0618 - val_acc: 0.9836\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0594 - acc: 0.9839 - val_loss: 0.0551 - val_acc: 0.9874\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0622 - acc: 0.9830 - val_loss: 0.0562 - val_acc: 0.9866\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0572 - acc: 0.9838 - val_loss: 0.0551 - val_acc: 0.9858\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0543 - acc: 0.9854 - val_loss: 0.0603 - val_acc: 0.9865\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0495 - acc: 0.9861 - val_loss: 0.0612 - val_acc: 0.9868\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0508 - acc: 0.9856 - val_loss: 0.0613 - val_acc: 0.9859\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0486 - acc: 0.9868 - val_loss: 0.0570 - val_acc: 0.9864\n",
      "Epoch 25/30\n",
      "120/240 [==============>...............] - ETA: 4s - loss: 0.0466 - acc: 0.9882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\020\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 209, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 151, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 66, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 848, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 580, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 611, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2420, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1661, in _filtered_call\n",
      "    return self._call_flat(\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1745, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 593, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\020\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[304,121,144] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[node gradient_tape/sequential_20/conv2d_58/Conv2DBackpropInput (defined at C:\\Users\\020\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:151) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_train_function_370725]\n",
      "\n",
      "Function call stack:\n",
      "train_function\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.9499 - acc: 0.6856 - val_loss: 0.2570 - val_acc: 0.9248\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3394 - acc: 0.9005 - val_loss: 0.1493 - val_acc: 0.9541\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2364 - acc: 0.9336 - val_loss: 0.1096 - val_acc: 0.9683\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1856 - acc: 0.9482 - val_loss: 0.0948 - val_acc: 0.9719\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1601 - acc: 0.9556 - val_loss: 0.0848 - val_acc: 0.9751\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1423 - acc: 0.9607 - val_loss: 0.0772 - val_acc: 0.9772\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1301 - acc: 0.9644 - val_loss: 0.0774 - val_acc: 0.9768\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1169 - acc: 0.9675 - val_loss: 0.0812 - val_acc: 0.9773\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.1093 - acc: 0.9695 - val_loss: 0.0765 - val_acc: 0.9771\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 0.1012 - acc: 0.9723 - val_loss: 0.0624 - val_acc: 0.9813\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.0948 - acc: 0.9746 - val_loss: 0.0645 - val_acc: 0.9824\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0858 - acc: 0.9762 - val_loss: 0.0576 - val_acc: 0.9835\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0816 - acc: 0.9774 - val_loss: 0.0633 - val_acc: 0.9816\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0766 - acc: 0.9792 - val_loss: 0.0593 - val_acc: 0.9826\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0751 - acc: 0.9793 - val_loss: 0.0582 - val_acc: 0.9834\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0710 - acc: 0.9805 - val_loss: 0.0619 - val_acc: 0.9839\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0709 - acc: 0.9802 - val_loss: 0.0582 - val_acc: 0.9844\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0665 - acc: 0.9811 - val_loss: 0.0557 - val_acc: 0.9845\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0643 - acc: 0.9827 - val_loss: 0.0666 - val_acc: 0.9850\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0590 - acc: 0.9835 - val_loss: 0.0648 - val_acc: 0.9831\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0586 - acc: 0.9840 - val_loss: 0.0687 - val_acc: 0.9832\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0537 - acc: 0.9850 - val_loss: 0.0582 - val_acc: 0.9854\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0528 - acc: 0.9854 - val_loss: 0.0618 - val_acc: 0.9853\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0506 - acc: 0.9856 - val_loss: 0.0612 - val_acc: 0.9839\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0527 - acc: 0.9851 - val_loss: 0.0513 - val_acc: 0.9871\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0499 - acc: 0.9858 - val_loss: 0.0652 - val_acc: 0.9838\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0471 - acc: 0.9863 - val_loss: 0.0570 - val_acc: 0.9840\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0477 - acc: 0.9869 - val_loss: 0.0663 - val_acc: 0.9841\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0465 - acc: 0.9871 - val_loss: 0.0579 - val_acc: 0.9858\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0441 - acc: 0.9883 - val_loss: 0.0567 - val_acc: 0.9876\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0592 - acc: 0.9860\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.8919 - acc: 0.7128 - val_loss: 0.2308 - val_acc: 0.9328\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3272 - acc: 0.9049 - val_loss: 0.1539 - val_acc: 0.9532\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.2219 - acc: 0.9373 - val_loss: 0.1072 - val_acc: 0.9684\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.1788 - acc: 0.9506 - val_loss: 0.0920 - val_acc: 0.9716\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1526 - acc: 0.9578 - val_loss: 0.1070 - val_acc: 0.9664\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1338 - acc: 0.9630 - val_loss: 0.0742 - val_acc: 0.9791\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.1188 - acc: 0.9674 - val_loss: 0.0724 - val_acc: 0.9805\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1088 - acc: 0.9707 - val_loss: 0.0655 - val_acc: 0.9821\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1002 - acc: 0.9730 - val_loss: 0.0631 - val_acc: 0.9815\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0920 - acc: 0.9747 - val_loss: 0.0663 - val_acc: 0.9824\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0863 - acc: 0.9765 - val_loss: 0.0574 - val_acc: 0.9850\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0803 - acc: 0.9777 - val_loss: 0.0601 - val_acc: 0.9832\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0739 - acc: 0.9801 - val_loss: 0.0617 - val_acc: 0.9844\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0693 - acc: 0.9817 - val_loss: 0.0599 - val_acc: 0.9826\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0695 - acc: 0.9811 - val_loss: 0.0603 - val_acc: 0.9842\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0611 - acc: 0.9831 - val_loss: 0.0572 - val_acc: 0.9849\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.0591 - acc: 0.9839 - val_loss: 0.0603 - val_acc: 0.9841\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0584 - acc: 0.9841 - val_loss: 0.0533 - val_acc: 0.9856\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0554 - acc: 0.9849 - val_loss: 0.0635 - val_acc: 0.9851\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0539 - acc: 0.9854 - val_loss: 0.0569 - val_acc: 0.9851\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0516 - acc: 0.9858 - val_loss: 0.0594 - val_acc: 0.9858\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0496 - acc: 0.9867 - val_loss: 0.0583 - val_acc: 0.9857\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0485 - acc: 0.9873 - val_loss: 0.0639 - val_acc: 0.9861\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0465 - acc: 0.9868 - val_loss: 0.0569 - val_acc: 0.9874\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0456 - acc: 0.9873 - val_loss: 0.0602 - val_acc: 0.9859\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0472 - acc: 0.9869 - val_loss: 0.0630 - val_acc: 0.9860\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0433 - acc: 0.9880 - val_loss: 0.0613 - val_acc: 0.9859\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0405 - acc: 0.9893 - val_loss: 0.0614 - val_acc: 0.9848\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0412 - acc: 0.9887 - val_loss: 0.0602 - val_acc: 0.9860\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0383 - acc: 0.9895 - val_loss: 0.0631 - val_acc: 0.9858\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0750 - acc: 0.9844\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 34ms/step - loss: 1.0041 - acc: 0.6717 - val_loss: 0.2725 - val_acc: 0.9204\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.4027 - acc: 0.8823 - val_loss: 0.1844 - val_acc: 0.9427\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2712 - acc: 0.9227 - val_loss: 0.1261 - val_acc: 0.9636\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2144 - acc: 0.9390 - val_loss: 0.1042 - val_acc: 0.9679\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1797 - acc: 0.9499 - val_loss: 0.0811 - val_acc: 0.9757\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1519 - acc: 0.9585 - val_loss: 0.0778 - val_acc: 0.9773\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.1362 - acc: 0.9631 - val_loss: 0.0705 - val_acc: 0.9787\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.1270 - acc: 0.9651 - val_loss: 0.0827 - val_acc: 0.9748\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.1119 - acc: 0.9695 - val_loss: 0.0646 - val_acc: 0.9807\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1062 - acc: 0.9707 - val_loss: 0.0709 - val_acc: 0.9783\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0960 - acc: 0.9735 - val_loss: 0.0616 - val_acc: 0.9829\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0915 - acc: 0.9756 - val_loss: 0.0595 - val_acc: 0.9833\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0839 - acc: 0.9775 - val_loss: 0.0648 - val_acc: 0.9817\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0819 - acc: 0.9781 - val_loss: 0.0578 - val_acc: 0.9844\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0777 - acc: 0.9792 - val_loss: 0.0639 - val_acc: 0.9826\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0744 - acc: 0.9795 - val_loss: 0.0562 - val_acc: 0.9851\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0693 - acc: 0.9808 - val_loss: 0.0575 - val_acc: 0.9846\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0651 - acc: 0.9823 - val_loss: 0.0596 - val_acc: 0.9842\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0631 - acc: 0.9824 - val_loss: 0.0593 - val_acc: 0.9847\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0603 - acc: 0.9831 - val_loss: 0.0544 - val_acc: 0.9852\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0583 - acc: 0.9841 - val_loss: 0.0565 - val_acc: 0.9859\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0576 - acc: 0.9843 - val_loss: 0.0628 - val_acc: 0.9835\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0526 - acc: 0.9851 - val_loss: 0.0645 - val_acc: 0.9825\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0522 - acc: 0.9857 - val_loss: 0.0580 - val_acc: 0.9852\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0502 - acc: 0.9860 - val_loss: 0.0646 - val_acc: 0.9843\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0471 - acc: 0.9869 - val_loss: 0.0704 - val_acc: 0.9842\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0466 - acc: 0.9862 - val_loss: 0.0644 - val_acc: 0.9848\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0439 - acc: 0.9872 - val_loss: 0.0590 - val_acc: 0.9861\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0446 - acc: 0.9877 - val_loss: 0.0629 - val_acc: 0.9847\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0436 - acc: 0.9876 - val_loss: 0.0666 - val_acc: 0.9855\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0745 - acc: 0.9837\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.9832 - acc: 0.6802 - val_loss: 0.2576 - val_acc: 0.9243\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3688 - acc: 0.8941 - val_loss: 0.1425 - val_acc: 0.9572\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 0.2531 - acc: 0.9289 - val_loss: 0.1097 - val_acc: 0.9662\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.1966 - acc: 0.9456 - val_loss: 0.1003 - val_acc: 0.9699\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1615 - acc: 0.9550 - val_loss: 0.0878 - val_acc: 0.9735\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1441 - acc: 0.9604 - val_loss: 0.0718 - val_acc: 0.9788\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1282 - acc: 0.9652 - val_loss: 0.0739 - val_acc: 0.9784\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1128 - acc: 0.9689 - val_loss: 0.0652 - val_acc: 0.9815\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1066 - acc: 0.9711 - val_loss: 0.0787 - val_acc: 0.9769\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0986 - acc: 0.9722 - val_loss: 0.0617 - val_acc: 0.9833\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0931 - acc: 0.9743 - val_loss: 0.0572 - val_acc: 0.9832\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.0866 - acc: 0.9760 - val_loss: 0.0593 - val_acc: 0.9833\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.0834 - acc: 0.9772 - val_loss: 0.0596 - val_acc: 0.9835\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0812 - acc: 0.9774 - val_loss: 0.0660 - val_acc: 0.9823\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0776 - acc: 0.9791 - val_loss: 0.0584 - val_acc: 0.9834\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0703 - acc: 0.9812 - val_loss: 0.0602 - val_acc: 0.9822\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0682 - acc: 0.9811 - val_loss: 0.0589 - val_acc: 0.9839\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0633 - acc: 0.9825 - val_loss: 0.0640 - val_acc: 0.9827\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0626 - acc: 0.9828 - val_loss: 0.0554 - val_acc: 0.9851\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0599 - acc: 0.9835 - val_loss: 0.0636 - val_acc: 0.9844\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0614 - acc: 0.9831 - val_loss: 0.0548 - val_acc: 0.9847\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0549 - acc: 0.9846 - val_loss: 0.0587 - val_acc: 0.9861\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.0547 - acc: 0.9847 - val_loss: 0.0656 - val_acc: 0.9836\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.0548 - acc: 0.9844 - val_loss: 0.0656 - val_acc: 0.9823\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0499 - acc: 0.9855 - val_loss: 0.0543 - val_acc: 0.9863\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0502 - acc: 0.9861 - val_loss: 0.0519 - val_acc: 0.9860\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0483 - acc: 0.9862 - val_loss: 0.0645 - val_acc: 0.9854\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.0479 - acc: 0.9875 - val_loss: 0.0663 - val_acc: 0.9824\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 0.0460 - acc: 0.9866 - val_loss: 0.0584 - val_acc: 0.9870\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0434 - acc: 0.9874 - val_loss: 0.0544 - val_acc: 0.9870\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.0562 - acc: 0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\020\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.98515 0.98435 0.98515     nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.8710 - acc: 0.7194 - val_loss: 0.2070 - val_acc: 0.9380\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.3111 - acc: 0.9125 - val_loss: 0.1393 - val_acc: 0.9601\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.2248 - acc: 0.9360 - val_loss: 0.1033 - val_acc: 0.9682\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.1902 - acc: 0.9465 - val_loss: 0.0866 - val_acc: 0.9729\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.1650 - acc: 0.9542 - val_loss: 0.0899 - val_acc: 0.9733\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.1516 - acc: 0.9582 - val_loss: 0.0753 - val_acc: 0.9785\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.1349 - acc: 0.9629 - val_loss: 0.0744 - val_acc: 0.9778\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.1247 - acc: 0.9663 - val_loss: 0.0731 - val_acc: 0.9802\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.1148 - acc: 0.9678 - val_loss: 0.0679 - val_acc: 0.9799\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 10s 35ms/step - loss: 0.1104 - acc: 0.9689 - val_loss: 0.0626 - val_acc: 0.9802\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 10s 35ms/step - loss: 0.1035 - acc: 0.9724 - val_loss: 0.0612 - val_acc: 0.9812\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0993 - acc: 0.9735 - val_loss: 0.0623 - val_acc: 0.9825\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0955 - acc: 0.9734 - val_loss: 0.0550 - val_acc: 0.9846\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0884 - acc: 0.9761 - val_loss: 0.0634 - val_acc: 0.9822\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.0843 - acc: 0.9766 - val_loss: 0.0644 - val_acc: 0.9821\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.0810 - acc: 0.9771 - val_loss: 0.0577 - val_acc: 0.9839\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.0765 - acc: 0.9787 - val_loss: 0.0592 - val_acc: 0.9825\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0715 - acc: 0.9802 - val_loss: 0.0601 - val_acc: 0.9830\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0723 - acc: 0.9799 - val_loss: 0.0588 - val_acc: 0.9848\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.0707 - acc: 0.9804 - val_loss: 0.0627 - val_acc: 0.9814\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0678 - acc: 0.9809 - val_loss: 0.0596 - val_acc: 0.9829\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0689 - acc: 0.9808 - val_loss: 0.0592 - val_acc: 0.9836\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0620 - acc: 0.9827 - val_loss: 0.0518 - val_acc: 0.9858\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0595 - acc: 0.9829 - val_loss: 0.0519 - val_acc: 0.9857\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0581 - acc: 0.9833 - val_loss: 0.0538 - val_acc: 0.9857\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0556 - acc: 0.9836 - val_loss: 0.0546 - val_acc: 0.9862\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0566 - acc: 0.9837 - val_loss: 0.0549 - val_acc: 0.9862\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 10s 33ms/step - loss: 0.0514 - acc: 0.9855 - val_loss: 0.0551 - val_acc: 0.9849\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.0528 - acc: 0.9853 - val_loss: 0.0579 - val_acc: 0.9847\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 10s 34ms/step - loss: 0.0486 - acc: 0.9857 - val_loss: 0.0533 - val_acc: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001ACB30CFCD0>,\n",
       "             param_grid={'learning_rate': [0.0025, 0.001],\n",
       "                         'optimizer': ['Adam', 'RMSProp']})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92b21d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0025, 'optimizer': 'Adam'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a2c0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# MODEL_DIR = '/model/'\n",
    "# if not os.path.exists(MODEL_DIR):\n",
    "#     os.mkdir(MODEL_DIR)\n",
    "# modelpath =\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "# # val_loss가 이전값보다 좋을 때 저장\n",
    "# checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# # 최적점을 찾아서 스톱\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "import os\n",
    "\n",
    "MODEL_DIR = '.\\\\model\\\\'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = '.\\\\model\\\\weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1,\n",
    "                               save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14fc9d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13262, saving model to .\\model\\weights.01-0.13.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13262 to 0.08711, saving model to .\\model\\weights.02-0.09.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08711 to 0.07756, saving model to .\\model\\weights.03-0.08.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07756 to 0.06143, saving model to .\\model\\weights.04-0.06.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06143\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06143\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06143 to 0.05616, saving model to .\\model\\weights.07-0.06.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05616\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05616\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05616\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05616 to 0.05292, saving model to .\\model\\weights.11-0.05.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05292\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05292\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.05292 to 0.05160, saving model to .\\model\\weights.14-0.05.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05160\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05160 to 0.05130, saving model to .\\model\\weights.16-0.05.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05130\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05130\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05130\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05130 to 0.05021, saving model to .\\model\\weights.20-0.05.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05021\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05021\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05021\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.05021\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05021\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n",
    "                   batch_size=200, verbose=0,\n",
    "                   callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "807b4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0596 - acc: 0.9868\n",
      "\n",
      "Test Accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nTest Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "y_vloss= history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1defc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 mnist 파라미터 튜닝을 진행하시오\n",
    "- optimizer와 learning-rate에 대하여 튜닝을 실시하시오\n",
    "    -최적의 파라미터를 출력\n",
    "- accuracy 그래프를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddec057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(3)\n",
    "# 784, TARGET : 3\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() # 784 FFNN\n",
    "# CNN 원래 이미지로 복원\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7045788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfn(optimizer = 'adam',learning_rate = 0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer(learning_rate=learning_rate),\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "new_model = KerasClassifier(build_fn=bfn, epochs=30, batch_size=200)\n",
    "\n",
    "param_grid = {'optimizer' : [\"Adam\",\"SGD\"],\n",
    "             'learning_rate' : [0.001,0.01],\n",
    "             'validation_data': [(x_te, y_te)],\n",
    "             'callbacks': [early_stopping_callback]}\n",
    "\n",
    "clf=GridSearchCV(estimator=new_model, param_grid=param_grid, n_jobs=-1, verbose=0)\n",
    "\n",
    "clf.fit(x_tr, y_tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
